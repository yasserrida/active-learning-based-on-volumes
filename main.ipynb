{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOP9F4FdCvZ9cJZYmbbsTRL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasserrida/active-learning-based-on-volumes/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVGivIAWIPFF"
      },
      "source": [
        "from strategies import RandomSampling, LeastConfidence, MarginSampling, EntropySampling, KMeansSampling\n",
        "from dataset import get_dataset, get_handler\n",
        "from model import get_net\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZsptOmIJW2Q"
      },
      "source": [
        "NB_INITIAL_ETIQUITE = 5000\n",
        "NB_QUERY = 1000\n",
        "NB_ITERATIONS = 10\n",
        "DATASET = 'MNIST'\n",
        "ARGS_POOL = {'MNIST':\n",
        "             {'n_epoch': 10, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
        "              'loader_tr_args': {'batch_size': 64, 'num_workers': 1},\n",
        "              'loader_te_args': {'batch_size': 1000, 'num_workers': 1},\n",
        "              'optimizer_args': {'lr': 0.01, 'momentum': 0.5}},\n",
        "             'FashionMNIST':\n",
        "             {'n_epoch': 10, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
        "              'loader_tr_args': {'batch_size': 64, 'num_workers': 1},\n",
        "              'loader_te_args': {'batch_size': 1000, 'num_workers': 1},\n",
        "              'optimizer_args': {'lr': 0.01, 'momentum': 0.5}},\n",
        "             'SVHN':\n",
        "             {'n_epoch': 20, 'transform': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))]),\n",
        "              'loader_tr_args': {'batch_size': 64, 'num_workers': 1},\n",
        "              'loader_te_args': {'batch_size': 1000, 'num_workers': 1},\n",
        "              'optimizer_args': {'lr': 0.01, 'momentum': 0.5}},\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwZnXrnhJYrC"
      },
      "source": [
        "# ========== générer un pool étiqueté initial\n",
        "def label_initial_data():\n",
        "    index_etiquite = np.zeros(n_pool, dtype=bool)\n",
        "    index_temp = np.arange(n_pool)\n",
        "    np.random.shuffle(index_temp)\n",
        "    index_etiquite[index_temp[:NB_INITIAL_ETIQUITE]] = True\n",
        "    return index_etiquite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysTVxN6sJbg-"
      },
      "source": [
        " # ========= Trainer et tester le modéle\n",
        "def main_function(strategy, index_etiquite):\n",
        "    strategy.train()\n",
        "    P = strategy.predict(x_test, y_test)\n",
        "    # ========= Calculer la precision Initial\n",
        "    presions = np.zeros(NB_ITERATIONS + 1)\n",
        "    presions[0] = 1.0 * (y_test == P).sum().item() / len(y_test)\n",
        "    print('\\nStratégie : ' + type(strategy).__name__)\n",
        "    print('\\tItération 0' + ' ............................. ' +'Précision: {}'.format(presions[0]))\n",
        "    # ========= Repeter pour le nombre d'iteration\n",
        "    for rd in range(1, NB_ITERATIONS + 1):\n",
        "        q_idxs = strategy.query(NB_QUERY)\n",
        "        index_etiquite[q_idxs] = True\n",
        "        # ========= mise a jour la dataset\n",
        "        strategy.update(index_etiquite)\n",
        "        strategy.train()\n",
        "        # ========= Calculer la precision\n",
        "        P = strategy.predict(x_test, y_test)\n",
        "        presions[rd] = 1.0 * (y_test == P).sum().item() / len(y_test)\n",
        "        print('\\tItération {}'.format(rd) + ' ............................. ' + 'Précision: {}'.format(presions[rd]))\n",
        "    return presions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-kC0UpJd03"
      },
      "source": [
        "result = []\n",
        "# ======= Définir le seed\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.backends.cudnn.enabled = False\n",
        "# ========== Diviser la dataset\n",
        "x_train, y_train, x_test, y_test = get_dataset(DATASET)\n",
        "x_train = x_train[:40000]\n",
        "y_train = y_train[:40000]\n",
        "# ======= Affichage des informations\n",
        "n_pool = len(y_train)\n",
        "print(\"\\nDataSet : \" + DATASET)\n",
        "print('\\tNombre de pool étiqueté: {}'.format(NB_INITIAL_ETIQUITE))\n",
        "print('\\tNombre de pool non étiqueté: {}'.format(n_pool - NB_INITIAL_ETIQUITE))\n",
        "print('\\tNombre de pool de test: {}'.format(len(y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEtWfRagJia_"
      },
      "source": [
        "# ========= Random Sampling\n",
        "strategy = RandomSampling(x_train, y_train, label_initial_data(), get_net(DATASET), get_handler(DATASET), ARGS_POOL[DATASET])\n",
        "result.append(main_function(strategy, label_initial_data()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}